# realtime_analyzer_upgraded.py

import cv2
import mediapipe as mp
import numpy as np
import joblib
from collections import deque
from PIL import ImageFont, ImageDraw, Image
import platform

print("--- ğŸš€ ì—…ê·¸ë ˆì´ë“œëœ ì‹¤ì‹œê°„ ë¶„ì„ê¸° ì‹œì‘ ---")

try:
    model_filename = "speed_classifier_upgraded.joblib"
    model = joblib.load(model_filename)
    print(f"âœ… ì—…ê·¸ë ˆì´ë“œëœ ëª¨ë¸ '{model_filename}' ë¡œë“œ ì™„ë£Œ!")
except FileNotFoundError:
    print(f"ğŸš¨ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼('{model_filename}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'train_upgraded_model.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    exit()

# (í°íŠ¸ ì„¤ì • ë° MediaPipe ì´ˆê¸°í™”ëŠ” ì´ì „ê³¼ ë™ì¼)
font_path = None; os_name = platform.system()
if os_name == "Darwin": font_path = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
elif os_name == "Linux": font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
try:
    if font_path: font = ImageFont.truetype(font_path, 24); status_font = ImageFont.truetype(font_path, 32)
    else: raise OSError
except OSError: font = None
mp_pose = mp.solutions.pose; pose = mp_pose.Pose(); mp_drawing = mp_solutions.drawing_utils
cap = cv2.VideoCapture(0) # ì‚¬ìš©í•  ì¹´ë©”ë¼ ì¸ë±ìŠ¤
if not cap.isOpened(): print("ğŸš¨ ì˜¤ë¥˜: ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); exit()

# ì‹¤ì‹œê°„ ë¶„ì„ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
prev_landmarks = None
prev_velocity = 0
recent_velocities = deque(maxlen=30)
recent_jerks = deque(maxlen=30)
recent_positions = deque(maxlen=30) # ìµœê·¼ 30í”„ë ˆì„ì˜ ê´€ì ˆ ì¤‘ì‹¬ì  ì €ì¥

KEY_JOINTS_TO_TRACK = [mp_pose.PoseLandmark.LEFT_WRIST, mp_pose.PoseLandmark.RIGHT_WRIST,
                       mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.RIGHT_ELBOW]

print("ğŸ‘€ ì›¹ìº  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret: break

    frame = cv2.flip(frame, 1)
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)

    status_kr = "ì•Œ ìˆ˜ ì—†ìŒ"; status_en = "Unknown"
    
    # í‘œì‹œí•  í˜„ì¬ íŠ¹ì§• ê°’ ì´ˆê¸°í™”
    speed_score, jerk_score, area_score = 0.0, 0.0, 0.0

    if results.pose_landmarks:
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        current_landmarks = results.pose_landmarks.landmark
        
        # í˜„ì¬ ê´€ì ˆë“¤ì˜ ì¤‘ì‹¬ ìœ„ì¹˜ ê³„ì‚°
        current_positions = []
        for joint_index in KEY_JOINTS_TO_TRACK:
            pos = current_landmarks[joint_index]
            current_positions.append([pos.x, pos.y])
        recent_positions.append(np.mean(current_positions, axis=0))

        if prev_landmarks:
            # ì†ë„ ê³„ì‚°
            frame_velocity = 0; num_joints = 0
            for joint_index in KEY_JOINTS_TO_TRACK:
                p_curr = current_landmarks[joint_index]; p_prev = prev_landmarks[joint_index]
                distance = np.sqrt((p_curr.x - p_prev.x)**2 + (p_curr.y - p_prev.y)**2)
                frame_velocity += distance; num_joints += 1
            if num_joints > 0:
                avg_frame_velocity = frame_velocity / num_joints
                recent_velocities.append(avg_frame_velocity)
                # ì €í¬ ê³„ì‚°
                jerk = abs(avg_frame_velocity - prev_velocity)
                recent_jerks.append(jerk)
                prev_velocity = avg_frame_velocity

        prev_landmarks = current_landmarks

        if len(recent_velocities) > 10:
            # 3ê°€ì§€ íŠ¹ì§•ì˜ ì‹¤ì‹œê°„ ê°’ ê³„ì‚°
            speed_score = np.mean(recent_velocities)
            jerk_score = np.mean(recent_jerks)
            
            # ì›€ì§ì„ ë²”ìœ„(ë©´ì ) ê³„ì‚°
            pos_array = np.array(recent_positions)
            max_x, max_y = np.max(pos_array, axis=0)
            min_x, min_y = np.min(pos_array, axis=0)
            area_score = (max_x - min_x) * (max_y - min_y)

            # ëª¨ë¸ì— 3ê°€ì§€ íŠ¹ì§•ì„ ëª¨ë‘ ì…ë ¥í•˜ì—¬ ì˜ˆì¸¡
            input_features = np.array([[speed_score, jerk_score, area_score]])
            prediction = model.predict(input_features)
            
            if prediction[0] == 1: status_kr, status_en = "ë¹ ë¦„", "Fast"
            else: status_kr, status_en = "ëŠë¦¼", "Slow"

    # ê²°ê³¼ í™”ë©´ì— í‘œì‹œ (3ê°€ì§€ íŠ¹ì§• ëª¨ë‘)
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.rectangle([(0,0), (450, 130)], fill=(0,0,0))
    
    if font:
        draw.text((10, 5), f"Speed: {speed_score:.4f}", font=font, fill=(255, 255, 255))
        draw.text((10, 35), f"Jerk: {jerk_score:.4f}", font=font, fill=(255, 255, 255))
        draw.text((10, 65), f"Area: {area_score:.4f}", font=font, fill=(255, 255, 255))
        color_kr = (0, 255, 0) if status_en == "Slow" else (255, 0, 0)
        draw.text((10, 95), f"ìƒíƒœ: {status_kr}", font=status_font, fill=color_kr)
        frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    
    cv2.imshow('Upgraded Real-time Analyzer', frame)
    if cv2.waitKey(5) & 0xFF == ord('q'): break

cap.release()
cv2.destroyAllWindows()
print("--- ğŸš€ ë¶„ì„ê¸° ì¢…ë£Œ ---")