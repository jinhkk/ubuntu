# train_upgraded_model.py

import cv2
import mediapipe as mp
import numpy as np
from pathlib import Path
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import joblib

print("--- ğŸš€ ì—…ê·¸ë ˆì´ë“œëœ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ (ë‹¤ì¤‘ íŠ¹ì§•) ---")

mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

def calculate_features(video_path):
    """
    ì˜ìƒì—ì„œ 3ê°€ì§€ íŠ¹ì§•(ì†ë„, ì €í¬, ë©´ì )ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.
    """
    video_path_str = str(video_path)
    cap = cv2.VideoCapture(video_path_str)
    if not cap.isOpened(): return None

    velocities = []
    jerks = []
    joint_positions = []
    
    prev_landmarks = None
    prev_velocity = 0

    KEY_JOINTS_TO_TRACK = [mp_pose.PoseLandmark.LEFT_WRIST, mp_pose.PoseLandmark.RIGHT_WRIST,
                           mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.RIGHT_ELBOW]

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)

        if results.pose_landmarks:
            current_landmarks = results.pose_landmarks.landmark
            
            # í˜„ì¬ í”„ë ˆì„ì˜ ê´€ì ˆ ìœ„ì¹˜ ì €ì¥ (ì›€ì§ì„ ë²”ìœ„ ê³„ì‚°ìš©)
            current_positions = []
            for joint_index in KEY_JOINTS_TO_TRACK:
                pos = current_landmarks[joint_index]
                current_positions.append([pos.x, pos.y])
            joint_positions.append(np.mean(current_positions, axis=0)) # 4ê°œ ê´€ì ˆì˜ ì¤‘ì‹¬ì  ì €ì¥

            if prev_landmarks:
                # 1. ì†ë„(Velocity) ê³„ì‚°
                frame_velocity = 0
                num_joints = 0
                for joint_index in KEY_JOINTS_TO_TRACK:
                    p_curr = current_landmarks[joint_index]
                    p_prev = prev_landmarks[joint_index]
                    distance = np.sqrt((p_curr.x - p_prev.x)**2 + (p_curr.y - p_prev.y)**2)
                    frame_velocity += distance
                    num_joints += 1
                
                if num_joints > 0:
                    avg_frame_velocity = frame_velocity / num_joints
                    velocities.append(avg_frame_velocity)

                    # 2. ì €í¬(Jerk) ê³„ì‚° (ì†ë„ì˜ ë³€í™”ìœ¨)
                    jerk = abs(avg_frame_velocity - prev_velocity)
                    jerks.append(jerk)
                    prev_velocity = avg_frame_velocity

            prev_landmarks = current_landmarks

    cap.release()
    cv2.destroyAllWindows()

    if not velocities: return [0.0, 0.0, 0.0]

    # 3. ì›€ì§ì„ ë²”ìœ„(Area) ê³„ì‚°
    if len(joint_positions) > 1:
        joint_positions = np.array(joint_positions)
        # ëª¨ë“  x, y ì¢Œí‘œì˜ ìµœì†Œ/ìµœëŒ€ê°’ì„ ì°¾ì•„ ì‚¬ê°í˜•ì˜ ë„ˆë¹„ì™€ ë†’ì´ë¥¼ ê³„ì‚°
        max_x, max_y = np.max(joint_positions, axis=0)
        min_x, min_y = np.min(joint_positions, axis=0)
        area = (max_x - min_x) * (max_y - min_y)
    else:
        area = 0.0

    # 3ê°€ì§€ íŠ¹ì§•ì˜ í‰ê· ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    return [np.mean(velocities), np.mean(jerks), area]

if __name__ == '__main__':
    try:
        script_dir = Path(__file__).resolve().parent
        fast_dir = script_dir / 'fast'
        slow_dir = script_dir / 'slow'
        fast_video_paths = sorted(list(fast_dir.glob('*.mp4')))
        slow_video_paths = sorted(list(slow_dir.glob('*.mp4')))
        if not fast_video_paths or not slow_video_paths:
            raise ValueError("ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        print("\n--- ğŸ“Š ë‹¤ì¤‘ íŠ¹ì§• ì¶”ì¶œ ì§„í–‰ ---")
        fast_features = [calculate_features(p) for p in fast_video_paths]
        slow_features = [calculate_features(p) for p in slow_video_paths]
        print("ëª¨ë“  ì˜ìƒì˜ íŠ¹ì§•(ì†ë„, ì €í¬, ë©´ì ) ê³„ì‚° ì™„ë£Œ.")

        # ë°ì´í„°ì…‹ ì¤€ë¹„ (ì´ì œ XëŠ” 3ê°œì˜ ì—´ì„ ê°€ì§)
        X = np.array(fast_features + slow_features)
        y = np.array([1] * len(fast_features) + [0] * len(slow_features))
        
        # ê²°ê³¼ í™•ì¸ìš© ì¶œë ¥
        print("\n--- ì¶”ì¶œëœ íŠ¹ì§• ë°ì´í„° ---")
        print("         Speed      Jerk       Area")
        for i, features in enumerate(X):
            label = "Fast" if y[i] == 1 else "Slow"
            print(f"Video {i+1} ({label}): {features[0]:.5f} | {features[1]:.5f} | {features[2]:.5f}")


        print("\n--- ğŸ¤– ì—…ê·¸ë ˆì´ë“œëœ ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
        model = LogisticRegression(random_state=42)
        model.fit(X, y)
        print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

        y_pred = model.predict(X)
        accuracy = accuracy_score(y, y_pred)
        print(f"\ní•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ì •í™•ë„: {accuracy * 100:.2f}%")

        model_filename = "speed_classifier_upgraded.joblib"
        joblib.dump(model, model_filename)
        print(f"\n--- ğŸ’¾ ì—…ê·¸ë ˆì´ë“œëœ ëª¨ë¸ì´ '{model_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ---")

    except Exception as e:
        print(f"\n--- ğŸš¨ ì˜¤ë¥˜ ë°œìƒ ğŸš¨ ---")
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")