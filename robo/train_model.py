# train_model.py (ë°ì´í„° ì¦ê°• ê¸°ëŠ¥ ì¶”ê°€)

import cv2
import mediapipe as mp
import numpy as np
from pathlib import Path
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import joblib

print("--- ğŸš€ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ (ë°ì´í„° ì¦ê°• í¬í•¨) ---")

# (calculate_speed í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ì™„ì „íˆ ë™ì¼í•©ë‹ˆë‹¤)
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
def calculate_speed(video_path):
    video_path_str = str(video_path)
    cap = cv2.VideoCapture(video_path_str)
    if not cap.isOpened(): return None
    velocities = []; prev_landmarks = None
    KEY_JOINTS_TO_TRACK = [mp_pose.PoseLandmark.LEFT_WRIST, mp_pose.PoseLandmark.RIGHT_WRIST, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.RIGHT_ELBOW]
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)
        if results.pose_landmarks:
            current_landmarks = results.pose_landmarks.landmark
            if prev_landmarks:
                frame_velocity = 0; num_joints = 0
                for joint_index in KEY_JOINTS_TO_TRACK:
                    p_curr = current_landmarks[joint_index]; p_prev = prev_landmarks[joint_index]
                    distance = np.sqrt((p_curr.x - p_prev.x)**2 + (p_curr.y - p_prev.y)**2)
                    frame_velocity += distance; num_joints += 1
                if num_joints > 0: velocities.append(frame_velocity / num_joints)
            prev_landmarks = current_landmarks
    cap.release()
    cv2.destroyAllWindows()
    if not velocities: return 0.0
    return np.mean(velocities)

if __name__ == '__main__':
    try:
        # 1. ê²½ë¡œ ì„¤ì • ë° íŒŒì¼ ë¡œë“œ
        script_dir = Path(__file__).resolve().parent
        fast_dir = script_dir / 'fast'
        slow_dir = script_dir / 'slow'
        fast_video_paths = sorted(list(fast_dir.glob('*.mp4')))
        slow_video_paths = sorted(list(slow_dir.glob('*.mp4')))
        if not fast_video_paths or not slow_video_paths:
            raise ValueError(f"ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. íŠ¹ì§• ì¶”ì¶œ
        print("\n--- ğŸ“Š íŠ¹ì§• ì¶”ì¶œ ì§„í–‰ ---")
        fast_scores = [calculate_speed(p) for p in fast_video_paths]
        slow_scores = [calculate_speed(p) for p in slow_video_paths]
        print("ëª¨ë“  ì›ë³¸ ì˜ìƒì˜ ì†ë„ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ.")

        # --- ğŸ”½ ë°ì´í„° ì¦ê°• (Data Augmentation) ğŸ”½ ---
        print("\n--- ğŸ§¬ ë°ì´í„° ì¦ê°• ì‹œì‘ ---")
        augmentation_factor = 5000 # ê° ì›ë³¸ ë°ì´í„°ë‹¹ 10ê°œì˜ ê°€ìƒ ë°ì´í„°ë¥¼ ìƒì„±
        noise_level = 0.0005 # ë…¸ì´ì¦ˆì˜ ê°•ë„ (ì•„ì£¼ ì‘ê²Œ ì„¤ì •)

        augmented_fast_scores = []
        for score in fast_scores:
            noise = np.random.normal(0, noise_level, augmentation_factor)
            augmented_fast_scores.extend(score + noise)

        augmented_slow_scores = []
        for score in slow_scores:
            noise = np.random.normal(0, noise_level, augmentation_factor)
            augmented_slow_scores.extend(score + noise)
        
        total_data_count = len(fast_scores) + len(slow_scores) + len(augmented_fast_scores) + len(augmented_slow_scores)
        print(f"ì›ë³¸ ë°ì´í„° 8ê°œ + ì¦ê°•ëœ ë°ì´í„° {len(augmented_fast_scores) + len(augmented_slow_scores)}ê°œ = ì´ {total_data_count}ê°œì˜ í•™ìŠµ ë°ì´í„° ìƒì„±.")
        # --- ğŸ”¼ ë°ì´í„° ì¦ê°• (Data Augmentation) ğŸ”¼ ---

        # 3. ë°ì´í„°ì…‹ ì¤€ë¹„ (ì›ë³¸ + ì¦ê°• ë°ì´í„°)
        all_fast_scores = fast_scores + augmented_fast_scores
        all_slow_scores = slow_scores + augmented_slow_scores
        
        X = np.array(all_fast_scores + all_slow_scores).reshape(-1, 1)
        y = np.array([1] * len(all_fast_scores) + [0] * len(all_slow_scores))

        # 4. ëª¨ë¸ í•™ìŠµ
        print("\n--- ğŸ¤– LogisticRegression ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
        model = LogisticRegression(random_state=42)
        model.fit(X, y)
        print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

        # 5. ëª¨ë¸ í‰ê°€ ë° ì„ê³„ê°’ í™•ì¸
        y_pred = model.predict(X)
        accuracy = accuracy_score(y, y_pred)
        print(f"\n--- ğŸ§  ëª¨ë¸ ë¶„ì„ ë° í‰ê°€ ---")
        print(f"ì¦ê°•ëœ ì „ì²´ í•™ìŠµ ë°ì´í„°({total_data_count}ê°œ)ì— ëŒ€í•œ ì˜ˆì¸¡ ì •í™•ë„: {accuracy * 100:.2f}%")

        if model.coef_[0][0] != 0:
            decision_boundary = -model.intercept_[0] / model.coef_[0][0]
            print(f"ëª¨ë¸ì´ í•™ìŠµí•œ ê²°ì • ê²½ê³„(Threshold): {decision_boundary:.5f}")

        # 6. ëª¨ë¸ íŒŒì¼ë¡œ ì €ì¥
        model_filename = "speed_classifier_augmented.joblib" # ì¦ê°• ëª¨ë¸ì€ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥
        joblib.dump(model, model_filename)
        print(f"\n--- ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ ---")
        print(f"ì¦ê°• ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì´ '{model_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\n--- ğŸš¨ ì˜¤ë¥˜ ë°œìƒ ğŸš¨ ---")
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")