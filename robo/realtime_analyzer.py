# realtime_analyzer.py (ì„ê³„ê°’ ìˆ˜ë™ ì¡°ì • ë²„ì „)

import cv2
import mediapipe as mp
import numpy as np
import joblib
from collections import deque
from PIL import ImageFont, ImageDraw, Image
import platform

print("--- ğŸš€ ì‹¤ì‹œê°„ ì†ë„ ë¶„ì„ê¸° ì‹œì‘ (ì„ê³„ê°’ ì¡°ì • ë²„ì „) ---")

try:
    model_filename = "speed_classifier.joblib"
    model = joblib.load(model_filename)
    print(f"âœ… ëª¨ë¸ '{model_filename}' ë¡œë“œ ì™„ë£Œ!")
except FileNotFoundError:
    print(f"ğŸš¨ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼('{model_filename}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# --- ğŸ”½ ëª¨ë¸ì˜ ì›ë˜ ì„ê³„ê°’ ê³„ì‚° ğŸ”½ ---
original_threshold = 0
if hasattr(model, 'coef_') and hasattr(model, 'intercept_'):
    if model.coef_[0][0] != 0:
        original_threshold = -model.intercept_[0] / model.coef_[0][0]
        print(f"ë¡œë“œëœ ëª¨ë¸ì˜ ì›ë˜ ì„ê³„ê°’: {original_threshold:.5f}")

ADJUSTMENT_FACTOR = 1.5 # ì´ ê°’ì„ 2.0 (2ë°°), 1.5 (1.5ë°°) ë“±ìœ¼ë¡œ ì¡°ì ˆ ê°€ëŠ¥
adjusted_threshold = original_threshold * ADJUSTMENT_FACTOR
print(f"ì‚¬ìš©ì ì¡°ì • ì„ê³„ê°’ ({ADJUSTMENT_FACTOR}ë°°): {adjusted_threshold:.5f}")


# (ì´í•˜ í°íŠ¸ ì„¤ì • ë° ì›¹ìº  ì´ˆê¸°í™” ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)
font_path = None; os_name = platform.system()
if os_name == "Darwin": font_path = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
elif os_name == "Linux": font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
try:
    if font_path:
        font = ImageFont.truetype(font_path, 30); status_font = ImageFont.truetype(font_path, 40)
        print(f"âœ… í°íŠ¸ ë¡œë“œ ì™„ë£Œ: {font_path} ({os_name})")
    else: raise OSError
except OSError:
    print(f"ğŸš¨ ê²½ê³ : {os_name}ì—ì„œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ë¬¸ìœ¼ë¡œë§Œ í‘œì‹œí•©ë‹ˆë‹¤."); font = None
mp_pose = mp.solutions.pose; pose = mp_pose.Pose(); mp_drawing = mp.solutions.drawing_utils
cap = cv2.VideoCapture(1);   # Mac = 1 ì›¹ìº  ì—°ê²° ì‹œ (0) ìœ¼ë¡œ ë³€ê²½ í•„
if not cap.isOpened(): print("ğŸš¨ ì˜¤ë¥˜: ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); exit()
prev_landmarks = None; recent_velocities = deque(maxlen=30) 
KEY_JOINTS_TO_TRACK = [mp_pose.PoseLandmark.LEFT_WRIST, mp_pose.PoseLandmark.RIGHT_WRIST, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.RIGHT_ELBOW]
print("ğŸ‘€ ì›¹ìº  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")


while cap.isOpened():
    ret, frame = cap.read()
    if not ret: break

    frame = cv2.flip(frame, 1)
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)

    current_speed_score = 0
    status_kr = "ì•Œ ìˆ˜ ì—†ìŒ"; status_en = "Unknown"

    if results.pose_landmarks:
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        current_landmarks = results.pose_landmarks.landmark
        
        if prev_landmarks:
            frame_velocity = 0; num_joints = 0
            for joint_index in KEY_JOINTS_TO_TRACK:
                p_curr = current_landmarks[joint_index]; p_prev = prev_landmarks[joint_index]
                distance = np.sqrt((p_curr.x - p_prev.x)**2 + (p_curr.y - p_prev.y)**2)
                frame_velocity += distance; num_joints += 1
            if num_joints > 0: recent_velocities.append(frame_velocity / num_joints)

        prev_landmarks = current_landmarks

        if len(recent_velocities) > 10:
            current_speed_score = np.mean(recent_velocities)
            
            # --- ğŸ”½ ëª¨ë¸ ì§ì ‘ ì˜ˆì¸¡ ëŒ€ì‹ , ì¡°ì •ëœ ì„ê³„ê°’ìœ¼ë¡œ íŒë‹¨ ğŸ”½ ---
            if current_speed_score > adjusted_threshold:
                status_kr = "ë¹ ë¦„"; status_en = "Fast"
            else:
                status_kr = "ëŠë¦¼"; status_en = "Slow"
    
    # (ì´í•˜ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° ë° í™”ë©´ ì¶œë ¥ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.rectangle([(0,0), (500, 100)], fill=(0,0,0))
    score_text = f"Speed Score: {current_speed_score:.5f}"
    threshold_text = f"Threshold: {adjusted_threshold:.5f}" # í˜„ì¬ ì ìš©ì¤‘ì¸ ì„ê³„ê°’ë„ í‘œì‹œ
    color_kr = (0, 255, 0) if status_en == "Slow" else (255, 0, 0)
    if font:
        draw.text((10, 5), score_text, font=font, fill=(255, 255, 255))
        draw.text((10, 35), threshold_text, font=font, fill=(255, 255, 150)) # ì„ê³„ê°’ì€ ë…¸ë€ìƒ‰ìœ¼ë¡œ
        draw.text((10, 65), f"ìƒíƒœ: {status_kr}", font=status_font, fill=color_kr)
        frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    else:
        # (ì˜ë¬¸ ì¶œë ¥ ë¶€ë¶„ì€ ìƒëµ)
        pass
    cv2.imshow('Real-time Speed Analysis', frame)
    if cv2.waitKey(5) & 0xFF == ord('q'): break

cap.release()
cv2.destroyAllWindows()
print("--- ğŸš€ ë¶„ì„ê¸° ì¢…ë£Œ ---")