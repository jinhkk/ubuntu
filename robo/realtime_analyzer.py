# realtime_analyzer.py

import cv2
import mediapipe as mp
import numpy as np
import joblib
from collections import deque # ìµœê·¼ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ deque ì¶”ê°€

print("--- ğŸš€ ì‹¤ì‹œê°„ ì†ë„ ë¶„ì„ê¸° ì‹œì‘ ---")

try:
    # 1. ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model_filename = "speed_classifier_augmented.joblib"
    model = joblib.load(model_filename)
    print(f"âœ… ëª¨ë¸ '{model_filename}' ë¡œë“œ ì™„ë£Œ!")
except FileNotFoundError:
    print(f"ğŸš¨ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼('{model_filename}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'train_model.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    exit()

# MediaPipe Pose ëª¨ë¸ ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

# 2. ì›¹ìº  ì—´ê¸°
cap = cv2.VideoCapture(0) # 0ì€ ê¸°ë³¸ ì›¹ìº ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
if not cap.isOpened():
    print("ğŸš¨ ì˜¤ë¥˜: ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# 3. ì‹¤ì‹œê°„ ë¶„ì„ì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
prev_landmarks = None
# ìµœê·¼ 30 í”„ë ˆì„ì˜ ì†ë„ ë°ì´í„°ë¥¼ ì €ì¥í•  ê³µê°„ (ì•½ 1ì´ˆ ë¶„ëŸ‰)
recent_velocities = deque(maxlen=30) 

KEY_JOINTS_TO_TRACK = [
    mp_pose.PoseLandmark.LEFT_WRIST, 
    mp_pose.PoseLandmark.RIGHT_WRIST,
    mp_pose.PoseLandmark.LEFT_ELBOW,
    mp_pose.PoseLandmark.RIGHT_ELBOW
]

print("ğŸ‘€ ì›¹ìº  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # 4. ì›¹ìº  ì˜ìƒ ì²˜ë¦¬
    # ê±°ìš¸ ëª¨ë“œì²˜ëŸ¼ ë³´ì´ë„ë¡ ì¢Œìš° ë°˜ì „
    frame = cv2.flip(frame, 1)
    
    # MediaPipe ì²˜ë¦¬ë¥¼ ìœ„í•´ ì´ë¯¸ì§€ í¬ë§· ë³€ê²½
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)

    current_speed_score = 0
    status = "ì•Œ ìˆ˜ ì—†ìŒ"

    if results.pose_landmarks:
        # ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
        current_landmarks = results.pose_landmarks.landmark
        
        if prev_landmarks:
            # 5. í”„ë ˆì„ ê°„ ì†ë„ ê³„ì‚°
            frame_velocity = 0
            num_joints = 0
            for joint_index in KEY_JOINTS_TO_TRACK:
                p_curr = current_landmarks[joint_index]
                p_prev = prev_landmarks[joint_index]
                distance = np.sqrt((p_curr.x - p_prev.x)**2 + (p_curr.y - p_prev.y)**2)
                frame_velocity += distance
                num_joints += 1
            
            if num_joints > 0:
                avg_frame_velocity = frame_velocity / num_joints
                recent_velocities.append(avg_frame_velocity)

        prev_landmarks = current_landmarks

        # 6. ì‹¤ì‹œê°„ ì†ë„ ì ìˆ˜ ê³„ì‚° ë° ì˜ˆì¸¡
        if len(recent_velocities) > 10: # ìµœì†Œ 10í”„ë ˆì„ ì´ìƒ ë°ì´í„°ê°€ ìŒ“ì˜€ì„ ë•Œë§Œ ê³„ì‚°
            current_speed_score = np.mean(recent_velocities)
            
            # ëª¨ë¸ë¡œ ì˜ˆì¸¡
            prediction = model.predict(np.array([[current_speed_score]]))
            status = "fast" if prediction[0] == 1 else "slow"

    # 7. ê²°ê³¼ í™”ë©´ì— í‘œì‹œ
    # ìƒíƒœ í‘œì‹œë¥¼ ìœ„í•œ ë°°ê²½ ì‚¬ê°í˜•
    cv2.rectangle(frame, (0, 0), (400, 80), (0, 0, 0), -1)
    
    # ì†ë„ ì ìˆ˜ í…ìŠ¤íŠ¸
    score_text = f"Speed Score: {current_speed_score:.5f}"
    cv2.putText(frame, score_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
    
    # ìƒíƒœ í…ìŠ¤íŠ¸ (ë¹ ë¦„/ëŠë¦¼)
    status_text = f"Status: {status}"
    color = (0, 255, 0) if status == "slow" else (0, 0, 255) # ëŠë¦¼ì€ ì´ˆë¡ìƒ‰, ë¹ ë¦„ì€ ë¹¨ê°„ìƒ‰
    cv2.putText(frame, status_text, (10, 65), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # í™”ë©´ì— ì˜ìƒ ì¶œë ¥
    cv2.imshow('Real-time Speed Analysis', frame)

    # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ë£¨í”„ íƒˆì¶œ
    if cv2.waitKey(5) & 0xFF == ord('q'):
        break

# 8. ìì› í•´ì œ
cap.release()
cv2.destroyAllWindows()
print("--- ğŸš€ ë¶„ì„ê¸° ì¢…ë£Œ ---")